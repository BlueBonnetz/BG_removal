{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09c36707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "## code from: https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n",
    "# __all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "#            'resnet152', 'ResNet34P','ResNet50S','ResNet50P','ResNet101P']\n",
    "#\n",
    "# resnet18_dir = '/local/sda4/yqian3/RoadNets/resnet_model/resnet18-5c106cde.pth'\n",
    "# resnet34_dir = '/local/sda4/yqian3/RoadNets/resnet_model/resnet34-333f7ec4.pth'\n",
    "# resnet50_dir = '/local/sda4/yqian3/RoadNets/resnet_model/resnet50-19c8e357.pth'\n",
    "# resnet101_dir = '/local/sda4/yqian3/RoadNets/resnet_model/resnet101-5d3b4d8f.pth'\n",
    "#\n",
    "# model_urls = {\n",
    "#     'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "#     'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "#     'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "#     'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "#     'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "# }\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class BasicBlockDe(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlockDe, self).__init__()\n",
    "\n",
    "        self.convRes = conv3x3(inplanes, planes, stride)\n",
    "        self.bnRes = nn.BatchNorm2d(planes)\n",
    "        self.reluRes = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.convRes(x)\n",
    "        residual = self.bnRes(residual)\n",
    "        residual = self.reluRes(residual)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class RefUnet(nn.Module):\n",
    "    def __init__(self, in_ch, inc_ch):\n",
    "        super(RefUnet, self).__init__()\n",
    "\n",
    "        self.conv0 = nn.Conv2d(in_ch, inc_ch, 3, padding=1)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inc_ch, 64, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(2, 2, ceil_mode=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(2, 2, ceil_mode=True)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.pool3 = nn.MaxPool2d(2, 2, ceil_mode=True)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.pool4 = nn.MaxPool2d(2, 2, ceil_mode=True)\n",
    "\n",
    "\n",
    "        self.conv5 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(64)\n",
    "        self.relu5 = nn.ReLU(inplace=True)\n",
    "\n",
    "\n",
    "        self.conv_d4 = nn.Conv2d(128, 64, 3, padding=1)\n",
    "        self.bn_d4 = nn.BatchNorm2d(64)\n",
    "        self.relu_d4 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv_d3 = nn.Conv2d(128, 64, 3, padding=1)\n",
    "        self.bn_d3 = nn.BatchNorm2d(64)\n",
    "        self.relu_d3 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv_d2 = nn.Conv2d(128, 64, 3, padding=1)\n",
    "        self.bn_d2 = nn.BatchNorm2d(64)\n",
    "        self.relu_d2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv_d1 = nn.Conv2d(128, 64, 3, padding=1)\n",
    "        self.bn_d1 = nn.BatchNorm2d(64)\n",
    "        self.relu_d1 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv_d0 = nn.Conv2d(64, 1, 3, padding=1)\n",
    "\n",
    "        self.upscore2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hx = x\n",
    "        hx = self.conv0(hx)\n",
    "\n",
    "        hx1 = self.relu1(self.bn1(self.conv1(hx)))\n",
    "        hx = self.pool1(hx1)\n",
    "\n",
    "        hx2 = self.relu2(self.bn2(self.conv2(hx)))\n",
    "        hx = self.pool2(hx2)\n",
    "\n",
    "        hx3 = self.relu3(self.bn3(self.conv3(hx)))\n",
    "        hx = self.pool3(hx3)\n",
    "\n",
    "        hx4 = self.relu4(self.bn4(self.conv4(hx)))\n",
    "        hx = self.pool4(hx4)\n",
    "\n",
    "        hx5 = self.relu5(self.bn5(self.conv5(hx)))\n",
    "\n",
    "        hx = self.upscore2(hx5)\n",
    "\n",
    "        d4 = self.relu_d4(self.bn_d4(self.conv_d4(torch.cat((hx, hx4), 1))))\n",
    "        hx = self.upscore2(d4)\n",
    "\n",
    "        d3 = self.relu_d3(self.bn_d3(self.conv_d3(torch.cat((hx, hx3), 1))))\n",
    "        hx = self.upscore2(d3)\n",
    "\n",
    "        d2 = self.relu_d2(self.bn_d2(self.conv_d2(torch.cat((hx, hx2), 1))))\n",
    "        hx = self.upscore2(d2)\n",
    "\n",
    "        d1 = self.relu_d1(self.bn_d1(self.conv_d1(torch.cat((hx, hx1), 1))))\n",
    "\n",
    "        residual = self.conv_d0(d1)\n",
    "\n",
    "        return x + residual\n",
    "\n",
    "\n",
    "class BASNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(BASNet, self).__init__()\n",
    "\n",
    "        resnet = models.resnet34(pretrained=True)\n",
    "\n",
    "        # -------------Encoder--------------\n",
    "\n",
    "        self.inconv = nn.Conv2d(n_channels, 64, 3, padding=1)\n",
    "        self.inbn = nn.BatchNorm2d(64)\n",
    "        self.inrelu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # stage 1\n",
    "        self.encoder1 = resnet.layer1  # 224\n",
    "        # stage 2\n",
    "        self.encoder2 = resnet.layer2  # 112\n",
    "        # stage 3\n",
    "        self.encoder3 = resnet.layer3  # 56\n",
    "        # stage 4\n",
    "        self.encoder4 = resnet.layer4  # 28\n",
    "\n",
    "        self.pool4 = nn.MaxPool2d(2, 2, ceil_mode=True)\n",
    "\n",
    "        # stage 5\n",
    "        self.resb5_1 = BasicBlock(512, 512)\n",
    "        self.resb5_2 = BasicBlock(512, 512)\n",
    "        self.resb5_3 = BasicBlock(512, 512)  # 14\n",
    "\n",
    "        self.pool5 = nn.MaxPool2d(2, 2, ceil_mode=True)\n",
    "\n",
    "        # stage 6\n",
    "        self.resb6_1 = BasicBlock(512, 512)\n",
    "        self.resb6_2 = BasicBlock(512, 512)\n",
    "        self.resb6_3 = BasicBlock(512, 512)  # 7\n",
    "\n",
    "        # -------------Bridge--------------\n",
    "\n",
    "        # stage Bridge\n",
    "        self.convbg_1 = nn.Conv2d(512, 512, 3, dilation=2, padding=2)  # 7\n",
    "        self.bnbg_1 = nn.BatchNorm2d(512)\n",
    "        self.relubg_1 = nn.ReLU(inplace=True)\n",
    "        self.convbg_m = nn.Conv2d(512, 512, 3, dilation=2, padding=2)\n",
    "        self.bnbg_m = nn.BatchNorm2d(512)\n",
    "        self.relubg_m = nn.ReLU(inplace=True)\n",
    "        self.convbg_2 = nn.Conv2d(512, 512, 3, dilation=2, padding=2)\n",
    "        self.bnbg_2 = nn.BatchNorm2d(512)\n",
    "        self.relubg_2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        # -------------Decoder--------------\n",
    "\n",
    "        # stage 6d\n",
    "        self.conv6d_1 = nn.Conv2d(1024, 512, 3, padding=1)  # 16\n",
    "        self.bn6d_1 = nn.BatchNorm2d(512)\n",
    "        self.relu6d_1 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv6d_m = nn.Conv2d(512, 512, 3, dilation=2, padding=2)  ###\n",
    "        self.bn6d_m = nn.BatchNorm2d(512)\n",
    "        self.relu6d_m = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv6d_2 = nn.Conv2d(512, 512, 3, dilation=2, padding=2)\n",
    "        self.bn6d_2 = nn.BatchNorm2d(512)\n",
    "        self.relu6d_2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        # stage 5d\n",
    "        self.conv5d_1 = nn.Conv2d(1024, 512, 3, padding=1)  # 16\n",
    "        self.bn5d_1 = nn.BatchNorm2d(512)\n",
    "        self.relu5d_1 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv5d_m = nn.Conv2d(512, 512, 3, padding=1)  ###\n",
    "        self.bn5d_m = nn.BatchNorm2d(512)\n",
    "        self.relu5d_m = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv5d_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.bn5d_2 = nn.BatchNorm2d(512)\n",
    "        self.relu5d_2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        # stage 4d\n",
    "        self.conv4d_1 = nn.Conv2d(1024, 512, 3, padding=1)  # 32\n",
    "        self.bn4d_1 = nn.BatchNorm2d(512)\n",
    "        self.relu4d_1 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv4d_m = nn.Conv2d(512, 512, 3, padding=1)  ###\n",
    "        self.bn4d_m = nn.BatchNorm2d(512)\n",
    "        self.relu4d_m = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv4d_2 = nn.Conv2d(512, 256, 3, padding=1)\n",
    "        self.bn4d_2 = nn.BatchNorm2d(256)\n",
    "        self.relu4d_2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        # stage 3d\n",
    "        self.conv3d_1 = nn.Conv2d(512, 256, 3, padding=1)  # 64\n",
    "        self.bn3d_1 = nn.BatchNorm2d(256)\n",
    "        self.relu3d_1 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv3d_m = nn.Conv2d(256, 256, 3, padding=1)  ###\n",
    "        self.bn3d_m = nn.BatchNorm2d(256)\n",
    "        self.relu3d_m = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv3d_2 = nn.Conv2d(256, 128, 3, padding=1)\n",
    "        self.bn3d_2 = nn.BatchNorm2d(128)\n",
    "        self.relu3d_2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        # stage 2d\n",
    "\n",
    "        self.conv2d_1 = nn.Conv2d(256, 128, 3, padding=1)  # 128\n",
    "        self.bn2d_1 = nn.BatchNorm2d(128)\n",
    "        self.relu2d_1 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2d_m = nn.Conv2d(128, 128, 3, padding=1)  ###\n",
    "        self.bn2d_m = nn.BatchNorm2d(128)\n",
    "        self.relu2d_m = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2d_2 = nn.Conv2d(128, 64, 3, padding=1)\n",
    "        self.bn2d_2 = nn.BatchNorm2d(64)\n",
    "        self.relu2d_2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        # stage 1d\n",
    "        self.conv1d_1 = nn.Conv2d(128, 64, 3, padding=1)  # 256\n",
    "        self.bn1d_1 = nn.BatchNorm2d(64)\n",
    "        self.relu1d_1 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv1d_m = nn.Conv2d(64, 64, 3, padding=1)  ###\n",
    "        self.bn1d_m = nn.BatchNorm2d(64)\n",
    "        self.relu1d_m = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv1d_2 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.bn1d_2 = nn.BatchNorm2d(64)\n",
    "        self.relu1d_2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        # -------------Bilinear Upsampling--------------\n",
    "        self.upscore6 = nn.Upsample(scale_factor=32, mode='bilinear', align_corners=False)  ###\n",
    "        self.upscore5 = nn.Upsample(scale_factor=16, mode='bilinear', align_corners=False)\n",
    "        self.upscore4 = nn.Upsample(scale_factor=8, mode='bilinear', align_corners=False)\n",
    "        self.upscore3 = nn.Upsample(scale_factor=4, mode='bilinear', align_corners=False)\n",
    "        self.upscore2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "\n",
    "        # -------------Side Output--------------\n",
    "        self.outconvb = nn.Conv2d(512, 1, 3, padding=1)\n",
    "        self.outconv6 = nn.Conv2d(512, 1, 3, padding=1)\n",
    "        self.outconv5 = nn.Conv2d(512, 1, 3, padding=1)\n",
    "        self.outconv4 = nn.Conv2d(256, 1, 3, padding=1)\n",
    "        self.outconv3 = nn.Conv2d(128, 1, 3, padding=1)\n",
    "        self.outconv2 = nn.Conv2d(64, 1, 3, padding=1)\n",
    "        self.outconv1 = nn.Conv2d(64, 1, 3, padding=1)\n",
    "\n",
    "        # -------------Refine Module-------------\n",
    "        self.refunet = RefUnet(1, 64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hx = x\n",
    "\n",
    "        # -------------Encoder-------------\n",
    "        hx = self.inconv(hx)\n",
    "        hx = self.inbn(hx)\n",
    "        hx = self.inrelu(hx)\n",
    "\n",
    "        h1 = self.encoder1(hx)  # 256\n",
    "        h2 = self.encoder2(h1)  # 128\n",
    "        h3 = self.encoder3(h2)  # 64\n",
    "        h4 = self.encoder4(h3)  # 32\n",
    "\n",
    "        hx = self.pool4(h4)  # 16\n",
    "\n",
    "        hx = self.resb5_1(hx)\n",
    "        hx = self.resb5_2(hx)\n",
    "        h5 = self.resb5_3(hx)\n",
    "\n",
    "        hx = self.pool5(h5)  # 8\n",
    "\n",
    "        hx = self.resb6_1(hx)\n",
    "        hx = self.resb6_2(hx)\n",
    "        h6 = self.resb6_3(hx)\n",
    "\n",
    "        #-------------Bridge-------------\n",
    "        hx = self.relubg_1(self.bnbg_1(self.convbg_1(h6)))  # 8\n",
    "        hx = self.relubg_m(self.bnbg_m(self.convbg_m(hx)))\n",
    "        hbg = self.relubg_2(self.bnbg_2(self.convbg_2(hx)))\n",
    "\n",
    "        # -------------Decoder-------------\n",
    "\n",
    "        hx = self.relu6d_1(self.bn6d_1(self.conv6d_1(torch.cat((hbg, h6), 1))))\n",
    "        hx = self.relu6d_m(self.bn6d_m(self.conv6d_m(hx)))\n",
    "        hd6 = self.relu6d_2(self.bn6d_2(self.conv6d_2(hx)))\n",
    "\n",
    "        hx = self.upscore2(hd6)  # 8 -> 16\n",
    "\n",
    "        hx = self.relu5d_1(self.bn5d_1(self.conv5d_1(torch.cat((hx, h5), 1))))\n",
    "        hx = self.relu5d_m(self.bn5d_m(self.conv5d_m(hx)))\n",
    "        hd5 = self.relu5d_2(self.bn5d_2(self.conv5d_2(hx)))\n",
    "\n",
    "        hx = self.upscore2(hd5)  # 16 -> 32\n",
    "\n",
    "        hx = self.relu4d_1(self.bn4d_1(self.conv4d_1(torch.cat((hx, h4), 1))))\n",
    "        hx = self.relu4d_m(self.bn4d_m(self.conv4d_m(hx)))\n",
    "        hd4 = self.relu4d_2(self.bn4d_2(self.conv4d_2(hx)))\n",
    "\n",
    "        hx = self.upscore2(hd4)  # 32 -> 64\n",
    "\n",
    "        hx = self.relu3d_1(self.bn3d_1(self.conv3d_1(torch.cat((hx, h3), 1))))\n",
    "        hx = self.relu3d_m(self.bn3d_m(self.conv3d_m(hx)))\n",
    "        hd3 = self.relu3d_2(self.bn3d_2(self.conv3d_2(hx)))\n",
    "\n",
    "        hx = self.upscore2(hd3)  # 64 -> 128\n",
    "\n",
    "        hx = self.relu2d_1(self.bn2d_1(self.conv2d_1(torch.cat((hx, h2), 1))))\n",
    "        hx = self.relu2d_m(self.bn2d_m(self.conv2d_m(hx)))\n",
    "        hd2 = self.relu2d_2(self.bn2d_2(self.conv2d_2(hx)))\n",
    "\n",
    "        hx = self.upscore2(hd2)  # 128 -> 256\n",
    "\n",
    "        hx = self.relu1d_1(self.bn1d_1(self.conv1d_1(torch.cat((hx, h1), 1))))\n",
    "        hx = self.relu1d_m(self.bn1d_m(self.conv1d_m(hx)))\n",
    "        hd1 = self.relu1d_2(self.bn1d_2(self.conv1d_2(hx)))\n",
    "\n",
    "        # -------------Side Output-------------\n",
    "        db = self.outconvb(hbg)\n",
    "        db = self.upscore6(db)  # 8->256\n",
    "\n",
    "        d6 = self.outconv6(hd6)\n",
    "        d6 = self.upscore6(d6)  # 8->256\n",
    "\n",
    "        d5 = self.outconv5(hd5)\n",
    "        d5 = self.upscore5(d5)  # 16->256\n",
    "\n",
    "        d4 = self.outconv4(hd4)\n",
    "        d4 = self.upscore4(d4)  # 32->256\n",
    "\n",
    "        d3 = self.outconv3(hd3)\n",
    "        d3 = self.upscore3(d3)  # 64->256\n",
    "\n",
    "        d2 = self.outconv2(hd2)\n",
    "        d2 = self.upscore2(d2)  # 128->256\n",
    "\n",
    "        d1 = self.outconv1(hd1)  # 256\n",
    "\n",
    "        # -------------Refine Module-------------\n",
    "        dout = self.refunet(d1)  # 256\n",
    "\n",
    "        return torch.sigmoid(dout), torch.sigmoid(d1), torch.sigmoid(d2), torch.sigmoid(d3), torch.sigmoid(\n",
    "            d4), torch.sigmoid(d5), torch.sigmoid(\n",
    "            d6), torch.sigmoid(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8dfc6c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage import io, transform\n",
    "\n",
    "import strings\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def model_detect(model_name):\n",
    "    \"\"\"Detects which model to use and returns its object\"\"\"\n",
    "    models_names = strings.MODELS_NAMES\n",
    "    if model_name in models_names:\n",
    "        if model_name == \"xception_model\" or model_name == \"mobile_net_model\":\n",
    "            return TFSegmentation(model_name)\n",
    "        elif \"u2net\" in model_name:\n",
    "            return U2NET(model_name)\n",
    "        elif \"basnet\" == model_name:\n",
    "            return BasNet(model_name)\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "class U2NET:\n",
    "    \"\"\"U^2-Net model interface\"\"\"\n",
    "\n",
    "    def __init__(self, name=\"u2net\"):\n",
    "        import torch\n",
    "        from torch.autograd import Variable\n",
    "        from u2net import U2NET as U2NET_DEEP\n",
    "        from u2net import U2NETP as U2NETP_DEEP\n",
    "        self.Variable = Variable\n",
    "        self.torch = torch\n",
    "        self.U2NET_DEEP = U2NET_DEEP\n",
    "        self.U2NETP_DEEP = U2NETP_DEEP\n",
    "\n",
    "        if name == 'u2net':  # Load model\n",
    "            logger.debug(\"Loading a U2NET model (176.6 mb) with better quality but slower processing.\")\n",
    "            net = self.U2NET_DEEP()\n",
    "        elif name == 'u2netp':\n",
    "            logger.debug(\"Loading a U2NETp model (4 mb) with lower quality but fast processing.\")\n",
    "            net = self.U2NETP_DEEP()\n",
    "        else:\n",
    "            raise Exception(\"Unknown u2net model!\")\n",
    "        try:\n",
    "            if self.torch.cuda.is_available():\n",
    "                net.load_state_dict(self.torch.load(os.path.join(\"models\", name, name + '.pth')))\n",
    "                net.cuda()\n",
    "            else:\n",
    "                net.load_state_dict(self.torch.load(os.path.join(\"models\", name, name + '.pth'), map_location=\"cpu\"))\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(\"No pre-trained model found! Run setup.sh or setup.bat to download it!\")\n",
    "        net.eval()\n",
    "        self.__net__ = net  # Define model\n",
    "\n",
    "    def process_image(self, data, preprocessing=None, postprocessing=None):\n",
    "        \"\"\"\n",
    "        Removes background from image and returns PIL RGBA Image.\n",
    "        :param data: Path to image or PIL image\n",
    "        :param preprocessing: Image Pre-Processing Algorithm Class (optional)\n",
    "        :param postprocessing: Image Post-Processing Algorithm Class (optional)\n",
    "        :return: PIL RGBA Image. If an error reading the image is detected, returns False.\n",
    "        \"\"\"\n",
    "        if isinstance(data, str):\n",
    "            logger.debug(\"Load image: {}\".format(data))\n",
    "        image, org_image = self.__load_image__(data)  # Load image\n",
    "        if image is False or org_image is False:\n",
    "            return False\n",
    "        if preprocessing:  # If an algorithm that preprocesses is specified,\n",
    "            # then this algorithm should immediately remove the background\n",
    "            image = preprocessing.run(self, image, org_image)\n",
    "        else:\n",
    "            image = self.__get_output__(image, org_image)  # If this is not, then just remove the background\n",
    "        if postprocessing:  # If a postprocessing algorithm is specified, we send it an image without a background\n",
    "            image = postprocessing.run(self, image, org_image)\n",
    "        return image\n",
    "\n",
    "    def __get_output__(self, image, org_image):\n",
    "        \"\"\"\n",
    "        Returns output from a neural network\n",
    "        :param image: Prepared Image\n",
    "        :param org_image: Original pil image\n",
    "        :return: Image without background\n",
    "        \"\"\"\n",
    "        start_time = time.time()  # Time counter\n",
    "        image = image.type(self.torch.FloatTensor)\n",
    "        if self.torch.cuda.is_available():\n",
    "            image = self.Variable(image.cuda())\n",
    "        else:\n",
    "            image = self.Variable(image)\n",
    "        mask, d2, d3, d4, d5, d6, d7 = self.__net__(image)  # Predict mask\n",
    "        logger.debug(\"Mask prediction completed\")\n",
    "        # Normalization\n",
    "        logger.debug(\"Mask normalization\")\n",
    "        mask = mask[:, 0, :, :]\n",
    "        mask = self.__normalize__(mask)\n",
    "        # Prepare mask\n",
    "        logger.debug(\"Prepare mask\")\n",
    "        mask = self.__prepare_mask__(mask, org_image.size)\n",
    "        # Apply mask to image\n",
    "        logger.debug(\"Apply mask to image\")\n",
    "        empty = Image.new(\"RGBA\", org_image.size)\n",
    "        image = Image.composite(org_image, empty, mask)\n",
    "        logger.debug(\"Finished! Time spent: {}\".format(time.time() - start_time))\n",
    "        return image\n",
    "\n",
    "    def __load_image__(self, data):\n",
    "        \"\"\"\n",
    "        Loads an image file for other processing\n",
    "        :param data: Path to image file or PIL image\n",
    "        :return: image tensor, original pil image\n",
    "        \"\"\"\n",
    "        image_size = 320  # Size of the input and output image for the model\n",
    "        if isinstance(data, str):\n",
    "            try:\n",
    "                image = io.imread(data)  # Load image if there is a path\n",
    "            except IOError:\n",
    "                logger.error('Cannot retrieve image. Please check file: ' + data)\n",
    "                return False, False\n",
    "            pil_image = Image.fromarray(image)\n",
    "        else:\n",
    "            image = np.array(data)  # Convert PIL image to numpy arr\n",
    "            pil_image = data\n",
    "        image = transform.resize(image, (image_size, image_size), mode='constant')  # Resize image\n",
    "        image = self.__ndrarray2tensor__(image)  # Convert image from numpy arr to tensor\n",
    "        return image, pil_image\n",
    "\n",
    "    def __ndrarray2tensor__(self, image: np.ndarray):\n",
    "        \"\"\"\n",
    "        Converts a NumPy array to a tensor\n",
    "        :param image: Image numpy array\n",
    "        :return: Image tensor\n",
    "        \"\"\"\n",
    "        tmp_img = np.zeros((image.shape[0], image.shape[1], 3))\n",
    "        image /= np.max(image)\n",
    "        if image.shape[2] == 1:\n",
    "            tmp_img[:, :, 0] = (image[:, :, 0] - 0.485) / 0.229\n",
    "            tmp_img[:, :, 1] = (image[:, :, 0] - 0.485) / 0.229\n",
    "            tmp_img[:, :, 2] = (image[:, :, 0] - 0.485) / 0.229\n",
    "        else:\n",
    "            tmp_img[:, :, 0] = (image[:, :, 0] - 0.485) / 0.229\n",
    "            tmp_img[:, :, 1] = (image[:, :, 1] - 0.456) / 0.224\n",
    "            tmp_img[:, :, 2] = (image[:, :, 2] - 0.406) / 0.225\n",
    "        tmp_img = tmp_img.transpose((2, 0, 1))\n",
    "        tmp_img = np.expand_dims(tmp_img, 0)\n",
    "        return self.torch.from_numpy(tmp_img)\n",
    "\n",
    "    def __normalize__(self, predicted):\n",
    "        \"\"\"Normalize the predicted map\"\"\"\n",
    "        ma = self.torch.max(predicted)\n",
    "        mi = self.torch.min(predicted)\n",
    "        out = (predicted - mi) / (ma - mi)\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def __prepare_mask__(predict, image_size):\n",
    "        \"\"\"Prepares mask\"\"\"\n",
    "        predict = predict.squeeze()\n",
    "        predict_np = predict.cpu().data.numpy()\n",
    "        mask = Image.fromarray(predict_np * 255).convert(\"L\")\n",
    "        mask = mask.resize(image_size, resample=Image.BILINEAR)\n",
    "        return mask\n",
    "\n",
    "\n",
    "class BasNet:\n",
    "    \"\"\"BasNet model interface\"\"\"\n",
    "\n",
    "    def __init__(self, name=\"basnet\"):\n",
    "        import torch\n",
    "        from torch.autograd import Variable\n",
    "        from libs.basnet import BASNet as BASNet_DEEP\n",
    "\n",
    "        self.Variable = Variable\n",
    "        self.torch = torch\n",
    "        self.BASNet_DEEP = BASNet_DEEP\n",
    "\n",
    "        if name == 'basnet':  # Load model\n",
    "            logger.debug(\"Loading a BASNet model.\")\n",
    "            net = self.BASNet_DEEP(3, 1)\n",
    "        else:\n",
    "            raise Exception(\"Unknown BASNet model\")\n",
    "        try:\n",
    "            if self.torch.cuda.is_available():\n",
    "                net.load_state_dict(self.torch.load(os.path.join(\"models\", name, name + '.pth')))\n",
    "                net.cuda()\n",
    "            else:\n",
    "                net.load_state_dict(self.torch.load(os.path.join(\"models\", name, name + '.pth'), map_location=\"cpu\"))\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(\"No pre-trained model found! Run setup.sh or setup.bat to download it!\")\n",
    "        net.eval()\n",
    "        self.__net__ = net  # Define model\n",
    "\n",
    "    def process_image(self, data, preprocessing=None, postprocessing=None):\n",
    "        \"\"\"\n",
    "        Removes background from image and returns PIL RGBA Image.\n",
    "        :param data: Path to image or PIL image\n",
    "        :param preprocessing: Image Pre-Processing Algorithm Class (optional)\n",
    "        :param postprocessing: Image Post-Processing Algorithm Class (optional)\n",
    "        :return: PIL RGBA Image. If an error reading the image is detected, returns False.\n",
    "        \"\"\"\n",
    "        if isinstance(data, str):\n",
    "            logger.debug(\"Load image: {}\".format(data))\n",
    "        image, orig_image = self.__load_image__(data)  # Load image\n",
    "        if image is False or orig_image is False:\n",
    "            return False\n",
    "        if preprocessing:  # If an algorithm that preprocesses is specified,\n",
    "            # then this algorithm should immediately remove the background\n",
    "            image = preprocessing.run(self, image, orig_image)\n",
    "        else:\n",
    "            image = self.__get_output__(image, orig_image)  # If this is not, then just remove the background\n",
    "        if postprocessing:  # If a postprocessing algorithm is specified, we send it an image without a background\n",
    "            image = postprocessing.run(self, image, orig_image)\n",
    "        return image\n",
    "\n",
    "    def __get_output__(self, image, org_image):\n",
    "        \"\"\"\n",
    "        Returns output from a neural network\n",
    "        :param image: Prepared Image\n",
    "        :param org_image: Original pil image\n",
    "        :return: Image without background\n",
    "        \"\"\"\n",
    "        start_time = time.time()  # Time counter\n",
    "        image = image.type(self.torch.FloatTensor)\n",
    "        if self.torch.cuda.is_available():\n",
    "            image = self.Variable(image.cuda())\n",
    "        else:\n",
    "            image = self.Variable(image)\n",
    "        mask, d2, d3, d4, d5, d6, d7, d8 = self.__net__(image)  # Predict mask\n",
    "        logger.debug(\"Mask prediction completed\")\n",
    "        # Normalization\n",
    "        logger.debug(\"Mask normalization\")\n",
    "        mask = mask[:, 0, :, :]\n",
    "        mask = self.__normalize__(mask)\n",
    "        # Prepare mask\n",
    "        logger.debug(\"Prepare mask\")\n",
    "        mask = self.__prepare_mask__(mask, org_image.size)\n",
    "        # Apply mask to image\n",
    "        logger.debug(\"Apply mask to image\")\n",
    "        empty = Image.new(\"RGBA\", org_image.size)\n",
    "        image = Image.composite(org_image, empty, mask)\n",
    "        logger.debug(\"Finished! Time spent: {}\".format(time.time() - start_time))\n",
    "        return image\n",
    "\n",
    "    def __load_image__(self, data):\n",
    "        \"\"\"\n",
    "        Loads an image file for other processing\n",
    "        :param data: Path to image file or PIL image\n",
    "        :return: image tensor, Original Pil Image\n",
    "        \"\"\"\n",
    "        image_size = 256  # Size of the input and output image for the model\n",
    "        if isinstance(data, str):\n",
    "            try:\n",
    "                image = io.imread(data)  # Load image if there is a path\n",
    "            except IOError:\n",
    "                logger.error('Cannot retrieve image. Please check file: ' + data)\n",
    "                return False, False\n",
    "            pil_image = Image.fromarray(image)\n",
    "        else:\n",
    "            image = np.array(data)  # Convert PIL image to numpy arr\n",
    "            pil_image = data\n",
    "        image = transform.resize(image, (image_size, image_size), mode='constant')  # Resize image\n",
    "        image = self.__ndrarray2tensor__(image)  # Convert image from numpy arr to tensor\n",
    "        return image, pil_image\n",
    "\n",
    "    def __ndrarray2tensor__(self, image: np.ndarray):\n",
    "        \"\"\"\n",
    "        Converts a NumPy array to a tensor\n",
    "        :param image: Image numpy array\n",
    "        :return: Image tensor\n",
    "        \"\"\"\n",
    "        tmp_img = np.zeros((image.shape[0], image.shape[1], 3))\n",
    "        image /= np.max(image)\n",
    "        if image.shape[2] == 1:\n",
    "            tmp_img[:, :, 0] = (image[:, :, 0] - 0.485) / 0.229\n",
    "            tmp_img[:, :, 1] = (image[:, :, 0] - 0.485) / 0.229\n",
    "            tmp_img[:, :, 2] = (image[:, :, 0] - 0.485) / 0.229\n",
    "        else:\n",
    "            tmp_img[:, :, 0] = (image[:, :, 0] - 0.485) / 0.229\n",
    "            tmp_img[:, :, 1] = (image[:, :, 1] - 0.456) / 0.224\n",
    "            tmp_img[:, :, 2] = (image[:, :, 2] - 0.406) / 0.225\n",
    "        tmp_img = tmp_img.transpose((2, 0, 1))\n",
    "        tmp_img = np.expand_dims(tmp_img, 0)\n",
    "        return self.torch.from_numpy(tmp_img)\n",
    "\n",
    "    def __normalize__(self, predicted):\n",
    "        \"\"\"Normalize the predicted map\"\"\"\n",
    "        ma = self.torch.max(predicted)\n",
    "        mi = self.torch.min(predicted)\n",
    "        out = (predicted - mi) / (ma - mi)\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def __prepare_mask__(predict, image_size):\n",
    "        \"\"\"Prepares mask\"\"\"\n",
    "        predict = predict.squeeze()\n",
    "        predict_np = predict.cpu().data.numpy()\n",
    "        mask = Image.fromarray(predict_np * 255).convert(\"L\")\n",
    "        mask = mask.resize(image_size, resample=Image.BILINEAR)\n",
    "        return mask\n",
    "\n",
    "\n",
    "class TFSegmentation(object):\n",
    "    \"\"\"Class to load Deeplabv3 model and run inference.\"\"\"\n",
    "    def __init__(self, model_type):\n",
    "        \"\"\"Creates and loads pretrained deeplab model.\"\"\"\n",
    "        import scipy.ndimage as ndi\n",
    "        import tensorflow as tf\n",
    "        self.tf = tf\n",
    "        self.ndi = ndi\n",
    "\n",
    "        # Environment init\n",
    "        self.INPUT_TENSOR_NAME = 'ImageTensor:0'\n",
    "        self.OUTPUT_TENSOR_NAME = 'SemanticPredictions:0'\n",
    "        self.INPUT_SIZE = 513\n",
    "        self.FROZEN_GRAPH_NAME = 'frozen_inference_graph'\n",
    "        # Start load process\n",
    "        self.graph = self.tf.Graph()\n",
    "        try:\n",
    "            graph_def = self.tf.compat.v1.GraphDef.FromString(open(os.path.join(\"models\", model_type, \"model\",\n",
    "                                                                                \"frozen_inference_graph.pb\"),\n",
    "                                                                   \"rb\").read())\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(\"No pre-trained model found! Run setup.sh or setup.bat to download it!\")\n",
    "        logger.warning(\"Loading a DeepLab model ({})! \"\n",
    "                       \"This is an outdated model with poorer image quality and processing time.\"\n",
    "                       \"Better use the U2NET model instead of this one!\".format(model_type))\n",
    "        if graph_def is None:\n",
    "            raise RuntimeError('Cannot find inference graph in tar archive.')\n",
    "        with self.graph.as_default():\n",
    "            self.tf.import_graph_def(graph_def, name='')\n",
    "        self.sess = self.tf.compat.v1.Session(graph=self.graph)\n",
    "\n",
    "    @staticmethod\n",
    "    def __load_image__(data):\n",
    "        \"\"\"\n",
    "        Loads an image file for other processing\n",
    "        :param data: Path to image file or PIL image\n",
    "        :return: Pil Image, Pil Image\n",
    "        \"\"\"\n",
    "        if isinstance(data, str):\n",
    "            try:\n",
    "                image = Image.open(data)  # Load image if there is a path\n",
    "            except IOError:\n",
    "                logger.error('Cannot retrieve image. Please check file: ' + data)\n",
    "                return False\n",
    "        else:\n",
    "            image = data\n",
    "        return image, image\n",
    "\n",
    "    def process_image(self, data, preprocessing=None, postprocessing=None):\n",
    "        \"\"\"\n",
    "        Removes background from image and returns PIL RGBA Image.\n",
    "        :param data: Path to image or PIL image\n",
    "        :param preprocessing: Image Pre-Processing Algorithm Class (optional)\n",
    "        :param postprocessing: Image Post-Processing Algorithm Class (optional)\n",
    "        :return: PIL RGBA Image. If an error reading the image is detected, returns False.\n",
    "        \"\"\"\n",
    "        if isinstance(data, str):\n",
    "            logger.debug(\"Load image: {}\".format(data))\n",
    "        image, org_image = self.__load_image__(data)  # Load image\n",
    "        if image is False or org_image is False:\n",
    "            return False\n",
    "        if preprocessing:  # If an algorithm that preprocesses is specified,\n",
    "            # then this algorithm should immediately remove the background\n",
    "            image = preprocessing.run(self, image, org_image)\n",
    "        else:\n",
    "            image = self.__get_output__(image, org_image)  # If this is not, then just remove the background\n",
    "        if postprocessing:  # If a postprocessing algorithm is specified, we send it an image without a background\n",
    "            image = postprocessing.run(self, image, org_image)\n",
    "        return image\n",
    "\n",
    "    def __get_output__(self, image, _=None):\n",
    "        \"\"\"\n",
    "        Returns output from a neural network\n",
    "        :param image: Prepared Image\n",
    "        :param _: Not used argument for compatibility with pre-processing module\n",
    "        :return: Image without background\n",
    "        \"\"\"\n",
    "        start_time = time.time()  # Time counter\n",
    "        seg_map = self.__predict__(image)\n",
    "        logger.debug('Finished mask creation')\n",
    "        image = image.convert('RGB')\n",
    "        logger.debug(\"Mask overlay completed\")\n",
    "        image = self.__draw_segment__(image, seg_map)\n",
    "        logger.debug(\"Finished! Time spent: {}\".format(time.time() - start_time))\n",
    "        return image\n",
    "\n",
    "    def __predict__(self, image):\n",
    "        \"\"\"Image processing.\"\"\"\n",
    "        # Get image size\n",
    "        width, height = image.size\n",
    "        # Calculate scale value\n",
    "        resize_ratio = 1.0 * self.INPUT_SIZE / max(width, height)\n",
    "        # Calculate future image size\n",
    "        target_size = (int(resize_ratio * width), int(resize_ratio * height))\n",
    "        # Resize image\n",
    "        resized_image = image.convert('RGB').resize(target_size, Image.ANTIALIAS)\n",
    "        # Send image to model\n",
    "        batch_seg_map = self.sess.run(\n",
    "            self.OUTPUT_TENSOR_NAME,\n",
    "            feed_dict={self.INPUT_TENSOR_NAME: [np.asarray(resized_image)]})\n",
    "        # Get model output\n",
    "        seg_map = batch_seg_map[0]\n",
    "        # Get new image size and original image size\n",
    "        width, height = resized_image.size\n",
    "        width2, height2 = image.size\n",
    "        # Calculate scale\n",
    "        scale_w = width2 / width\n",
    "        scale_h = height2 / height\n",
    "        # Zoom numpy array for original image\n",
    "        seg_map = self.ndi.zoom(seg_map, (scale_h, scale_w))\n",
    "        return seg_map\n",
    "\n",
    "    @staticmethod\n",
    "    def __draw_segment__(image, alpha_channel):\n",
    "        \"\"\"Postprocessing. Returns complete image.\"\"\"\n",
    "        # Get image size\n",
    "        width, height = image.size\n",
    "        # Create empty numpy array\n",
    "        dummy_img = np.zeros([height, width, 4], dtype=np.uint8)\n",
    "        # Create alpha layer from model output\n",
    "        for x in range(width):\n",
    "            for y in range(height):\n",
    "                color = alpha_channel[y, x]\n",
    "                (r, g, b) = image.getpixel((x, y))\n",
    "                if color == 0:\n",
    "                    dummy_img[y, x, 3] = 0\n",
    "                else:\n",
    "                    dummy_img[y, x] = [r, g, b, 255]\n",
    "        # Restore image object from numpy array\n",
    "        img = Image.fromarray(dummy_img)\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09de7535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class REBNCONV(nn.Module):\n",
    "    def __init__(self, in_ch=3, out_ch=3, dirate=1):\n",
    "        super(REBNCONV, self).__init__()\n",
    "\n",
    "        self.conv_s1 = nn.Conv2d(in_ch, out_ch, 3, padding=1 * dirate, dilation=1 * dirate)\n",
    "        self.bn_s1 = nn.BatchNorm2d(out_ch)\n",
    "        self.relu_s1 = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hx = x\n",
    "        xout = self.relu_s1(self.bn_s1(self.conv_s1(hx)))\n",
    "\n",
    "        return xout\n",
    "\n",
    "\n",
    "# upsample tensor 'src' to have the same spatial size with tensor 'tar'\n",
    "def _upsample_like(src, tar):\n",
    "    src = F.interpolate(src, size=tar.shape[2:], mode='bilinear', align_corners=False)\n",
    "\n",
    "    return src\n",
    "\n",
    "\n",
    "# RSU-7\n",
    "class RSU7(nn.Module):  # UNet07DRES(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
    "        super(RSU7, self).__init__()\n",
    "\n",
    "        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)\n",
    "\n",
    "        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
    "        self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.rebnconv5 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
    "        self.pool5 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.rebnconv6 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
    "\n",
    "        self.rebnconv7 = REBNCONV(mid_ch, mid_ch, dirate=2)\n",
    "\n",
    "        self.rebnconv6d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
    "        self.rebnconv5d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
    "        self.rebnconv4d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
    "        self.rebnconv3d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
    "        self.rebnconv2d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
    "        self.rebnconv1d = REBNCONV(mid_ch * 2, out_ch, dirate=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hx = x\n",
    "        hxin = self.rebnconvin(hx)\n",
    "\n",
    "        hx1 = self.rebnconv1(hxin)\n",
    "        hx = self.pool1(hx1)\n",
    "\n",
    "        hx2 = self.rebnconv2(hx)\n",
    "        hx = self.pool2(hx2)\n",
    "\n",
    "        hx3 = self.rebnconv3(hx)\n",
    "        hx = self.pool3(hx3)\n",
    "\n",
    "        hx4 = self.rebnconv4(hx)\n",
    "        hx = self.pool4(hx4)\n",
    "\n",
    "        hx5 = self.rebnconv5(hx)\n",
    "        hx = self.pool5(hx5)\n",
    "\n",
    "        hx6 = self.rebnconv6(hx)\n",
    "\n",
    "        hx7 = self.rebnconv7(hx6)\n",
    "\n",
    "        hx6d = self.rebnconv6d(torch.cat((hx7, hx6), 1))\n",
    "        hx6dup = _upsample_like(hx6d, hx5)\n",
    "\n",
    "        hx5d = self.rebnconv5d(torch.cat((hx6dup, hx5), 1))\n",
    "        hx5dup = _upsample_like(hx5d, hx4)\n",
    "\n",
    "        hx4d = self.rebnconv4d(torch.cat((hx5dup, hx4), 1))\n",
    "        hx4dup = _upsample_like(hx4d, hx3)\n",
    "\n",
    "        hx3d = self.rebnconv3d(torch.cat((hx4dup, hx3), 1))\n",
    "        hx3dup = _upsample_like(hx3d, hx2)\n",
    "\n",
    "        hx2d = self.rebnconv2d(torch.cat((hx3dup, hx2), 1))\n",
    "        hx2dup = _upsample_like(hx2d, hx1)\n",
    "\n",
    "        hx1d = self.rebnconv1d(torch.cat((hx2dup, hx1), 1))\n",
    "\n",
    "        return hx1d + hxin\n",
    "\n",
    "\n",
    "### RSU-6 ###\n",
    "class RSU6(nn.Module):  # UNet06DRES(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
    "        super(RSU6, self).__init__()\n",
    "\n",
    "        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)\n",
    "\n",
    "        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
    "        self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.rebnconv5 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
    "\n",
    "        self.rebnconv6 = REBNCONV(mid_ch, mid_ch, dirate=2)\n",
    "\n",
    "        self.rebnconv5d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
    "        self.rebnconv4d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
    "        self.rebnconv3d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
    "        self.rebnconv2d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
    "        self.rebnconv1d = REBNCONV(mid_ch * 2, out_ch, dirate=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hx = x\n",
    "\n",
    "        hxin = self.rebnconvin(hx)\n",
    "\n",
    "        hx1 = self.rebnconv1(hxin)\n",
    "        hx = self.pool1(hx1)\n",
    "\n",
    "        hx2 = self.rebnconv2(hx)\n",
    "        hx = self.pool2(hx2)\n",
    "\n",
    "        hx3 = self.rebnconv3(hx)\n",
    "        hx = self.pool3(hx3)\n",
    "\n",
    "        hx4 = self.rebnconv4(hx)\n",
    "        hx = self.pool4(hx4)\n",
    "\n",
    "        hx5 = self.rebnconv5(hx)\n",
    "\n",
    "        hx6 = self.rebnconv6(hx5)\n",
    "\n",
    "        hx5d = self.rebnconv5d(torch.cat((hx6, hx5), 1))\n",
    "        hx5dup = _upsample_like(hx5d, hx4)\n",
    "\n",
    "        hx4d = self.rebnconv4d(torch.cat((hx5dup, hx4), 1))\n",
    "        hx4dup = _upsample_like(hx4d, hx3)\n",
    "\n",
    "        hx3d = self.rebnconv3d(torch.cat((hx4dup, hx3), 1))\n",
    "        hx3dup = _upsample_like(hx3d, hx2)\n",
    "\n",
    "        hx2d = self.rebnconv2d(torch.cat((hx3dup, hx2), 1))\n",
    "        hx2dup = _upsample_like(hx2d, hx1)\n",
    "\n",
    "        hx1d = self.rebnconv1d(torch.cat((hx2dup, hx1), 1))\n",
    "\n",
    "        return hx1d + hxin\n",
    "\n",
    "\n",
    "### RSU-5 ###\n",
    "class RSU5(nn.Module):  # UNet05DRES(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
    "        super(RSU5, self).__init__()\n",
    "\n",
    "        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)\n",
    "\n",
    "        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
    "\n",
    "        self.rebnconv5 = REBNCONV(mid_ch, mid_ch, dirate=2)\n",
    "\n",
    "        self.rebnconv4d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
    "        self.rebnconv3d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
    "        self.rebnconv2d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
    "        self.rebnconv1d = REBNCONV(mid_ch * 2, out_ch, dirate=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hx = x\n",
    "\n",
    "        hxin = self.rebnconvin(hx)\n",
    "\n",
    "        hx1 = self.rebnconv1(hxin)\n",
    "        hx = self.pool1(hx1)\n",
    "\n",
    "        hx2 = self.rebnconv2(hx)\n",
    "        hx = self.pool2(hx2)\n",
    "\n",
    "        hx3 = self.rebnconv3(hx)\n",
    "        hx = self.pool3(hx3)\n",
    "\n",
    "        hx4 = self.rebnconv4(hx)\n",
    "\n",
    "        hx5 = self.rebnconv5(hx4)\n",
    "\n",
    "        hx4d = self.rebnconv4d(torch.cat((hx5, hx4), 1))\n",
    "        hx4dup = _upsample_like(hx4d, hx3)\n",
    "\n",
    "        hx3d = self.rebnconv3d(torch.cat((hx4dup, hx3), 1))\n",
    "        hx3dup = _upsample_like(hx3d, hx2)\n",
    "\n",
    "        hx2d = self.rebnconv2d(torch.cat((hx3dup, hx2), 1))\n",
    "        hx2dup = _upsample_like(hx2d, hx1)\n",
    "\n",
    "        hx1d = self.rebnconv1d(torch.cat((hx2dup, hx1), 1))\n",
    "\n",
    "        return hx1d + hxin\n",
    "\n",
    "\n",
    "### RSU-4 ###\n",
    "class RSU4(nn.Module):  # UNet04DRES(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
    "        super(RSU4, self).__init__()\n",
    "\n",
    "        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)\n",
    "\n",
    "        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
    "\n",
    "        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=2)\n",
    "\n",
    "        self.rebnconv3d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
    "        self.rebnconv2d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
    "        self.rebnconv1d = REBNCONV(mid_ch * 2, out_ch, dirate=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hx = x\n",
    "\n",
    "        hxin = self.rebnconvin(hx)\n",
    "\n",
    "        hx1 = self.rebnconv1(hxin)\n",
    "        hx = self.pool1(hx1)\n",
    "\n",
    "        hx2 = self.rebnconv2(hx)\n",
    "        hx = self.pool2(hx2)\n",
    "\n",
    "        hx3 = self.rebnconv3(hx)\n",
    "\n",
    "        hx4 = self.rebnconv4(hx3)\n",
    "\n",
    "        hx3d = self.rebnconv3d(torch.cat((hx4, hx3), 1))\n",
    "        hx3dup = _upsample_like(hx3d, hx2)\n",
    "\n",
    "        hx2d = self.rebnconv2d(torch.cat((hx3dup, hx2), 1))\n",
    "        hx2dup = _upsample_like(hx2d, hx1)\n",
    "\n",
    "        hx1d = self.rebnconv1d(torch.cat((hx2dup, hx1), 1))\n",
    "\n",
    "        return hx1d + hxin\n",
    "\n",
    "\n",
    "### RSU-4F ###\n",
    "class RSU4F(nn.Module):  # UNet04FRES(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
    "        super(RSU4F, self).__init__()\n",
    "\n",
    "        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)\n",
    "\n",
    "        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)\n",
    "        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=2)\n",
    "        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=4)\n",
    "\n",
    "        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=8)\n",
    "\n",
    "        self.rebnconv3d = REBNCONV(mid_ch * 2, mid_ch, dirate=4)\n",
    "        self.rebnconv2d = REBNCONV(mid_ch * 2, mid_ch, dirate=2)\n",
    "        self.rebnconv1d = REBNCONV(mid_ch * 2, out_ch, dirate=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hx = x\n",
    "\n",
    "        hxin = self.rebnconvin(hx)\n",
    "\n",
    "        hx1 = self.rebnconv1(hxin)\n",
    "        hx2 = self.rebnconv2(hx1)\n",
    "        hx3 = self.rebnconv3(hx2)\n",
    "\n",
    "        hx4 = self.rebnconv4(hx3)\n",
    "\n",
    "        hx3d = self.rebnconv3d(torch.cat((hx4, hx3), 1))\n",
    "        hx2d = self.rebnconv2d(torch.cat((hx3d, hx2), 1))\n",
    "        hx1d = self.rebnconv1d(torch.cat((hx2d, hx1), 1))\n",
    "\n",
    "        return hx1d + hxin\n",
    "\n",
    "\n",
    "##### U^2-Net ####\n",
    "class U2NET(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch=3, out_ch=1):\n",
    "        super(U2NET, self).__init__()\n",
    "\n",
    "        self.stage1 = RSU7(in_ch, 32, 64)\n",
    "        self.pool12 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.stage2 = RSU6(64, 32, 128)\n",
    "        self.pool23 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.stage3 = RSU5(128, 64, 256)\n",
    "        self.pool34 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.stage4 = RSU4(256, 128, 512)\n",
    "        self.pool45 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.stage5 = RSU4F(512, 256, 512)\n",
    "        self.pool56 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.stage6 = RSU4F(512, 256, 512)\n",
    "\n",
    "        # decoder\n",
    "        self.stage5d = RSU4F(1024, 256, 512)\n",
    "        self.stage4d = RSU4(1024, 128, 256)\n",
    "        self.stage3d = RSU5(512, 64, 128)\n",
    "        self.stage2d = RSU6(256, 32, 64)\n",
    "        self.stage1d = RSU7(128, 16, 64)\n",
    "\n",
    "        self.side1 = nn.Conv2d(64, out_ch, 3, padding=1)\n",
    "        self.side2 = nn.Conv2d(64, out_ch, 3, padding=1)\n",
    "        self.side3 = nn.Conv2d(128, out_ch, 3, padding=1)\n",
    "        self.side4 = nn.Conv2d(256, out_ch, 3, padding=1)\n",
    "        self.side5 = nn.Conv2d(512, out_ch, 3, padding=1)\n",
    "        self.side6 = nn.Conv2d(512, out_ch, 3, padding=1)\n",
    "\n",
    "        self.outconv = nn.Conv2d(6, out_ch, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hx = x\n",
    "\n",
    "        # stage 1\n",
    "        hx1 = self.stage1(hx)\n",
    "        hx = self.pool12(hx1)\n",
    "\n",
    "        # stage 2\n",
    "        hx2 = self.stage2(hx)\n",
    "        hx = self.pool23(hx2)\n",
    "\n",
    "        # stage 3\n",
    "        hx3 = self.stage3(hx)\n",
    "        hx = self.pool34(hx3)\n",
    "\n",
    "        # stage 4\n",
    "        hx4 = self.stage4(hx)\n",
    "        hx = self.pool45(hx4)\n",
    "\n",
    "        # stage 5\n",
    "        hx5 = self.stage5(hx)\n",
    "        hx = self.pool56(hx5)\n",
    "\n",
    "        # stage 6\n",
    "        hx6 = self.stage6(hx)\n",
    "        hx6up = _upsample_like(hx6, hx5)\n",
    "\n",
    "        # -------------------- decoder --------------------\n",
    "        hx5d = self.stage5d(torch.cat((hx6up, hx5), 1))\n",
    "        hx5dup = _upsample_like(hx5d, hx4)\n",
    "\n",
    "        hx4d = self.stage4d(torch.cat((hx5dup, hx4), 1))\n",
    "        hx4dup = _upsample_like(hx4d, hx3)\n",
    "\n",
    "        hx3d = self.stage3d(torch.cat((hx4dup, hx3), 1))\n",
    "        hx3dup = _upsample_like(hx3d, hx2)\n",
    "\n",
    "        hx2d = self.stage2d(torch.cat((hx3dup, hx2), 1))\n",
    "        hx2dup = _upsample_like(hx2d, hx1)\n",
    "\n",
    "        hx1d = self.stage1d(torch.cat((hx2dup, hx1), 1))\n",
    "\n",
    "        # side output\n",
    "        d1 = self.side1(hx1d)\n",
    "\n",
    "        d2 = self.side2(hx2d)\n",
    "        d2 = _upsample_like(d2, d1)\n",
    "\n",
    "        d3 = self.side3(hx3d)\n",
    "        d3 = _upsample_like(d3, d1)\n",
    "\n",
    "        d4 = self.side4(hx4d)\n",
    "        d4 = _upsample_like(d4, d1)\n",
    "\n",
    "        d5 = self.side5(hx5d)\n",
    "        d5 = _upsample_like(d5, d1)\n",
    "\n",
    "        d6 = self.side6(hx6)\n",
    "        d6 = _upsample_like(d6, d1)\n",
    "\n",
    "        d0 = self.outconv(torch.cat((d1, d2, d3, d4, d5, d6), 1))\n",
    "\n",
    "        return torch.sigmoid(d0), torch.sigmoid(d1), torch.sigmoid(d2), torch.sigmoid(d3), torch.sigmoid(\n",
    "            d4), torch.sigmoid(d5), torch.sigmoid(d6)\n",
    "\n",
    "\n",
    "### U^2-Net small ###\n",
    "class U2NETP(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch=3, out_ch=1):\n",
    "        super(U2NETP, self).__init__()\n",
    "\n",
    "        self.stage1 = RSU7(in_ch, 16, 64)\n",
    "        self.pool12 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.stage2 = RSU6(64, 16, 64)\n",
    "        self.pool23 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.stage3 = RSU5(64, 16, 64)\n",
    "        self.pool34 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.stage4 = RSU4(64, 16, 64)\n",
    "        self.pool45 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.stage5 = RSU4F(64, 16, 64)\n",
    "        self.pool56 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.stage6 = RSU4F(64, 16, 64)\n",
    "\n",
    "        # decoder\n",
    "        self.stage5d = RSU4F(128, 16, 64)\n",
    "        self.stage4d = RSU4(128, 16, 64)\n",
    "        self.stage3d = RSU5(128, 16, 64)\n",
    "        self.stage2d = RSU6(128, 16, 64)\n",
    "        self.stage1d = RSU7(128, 16, 64)\n",
    "\n",
    "        self.side1 = nn.Conv2d(64, out_ch, 3, padding=1)\n",
    "        self.side2 = nn.Conv2d(64, out_ch, 3, padding=1)\n",
    "        self.side3 = nn.Conv2d(64, out_ch, 3, padding=1)\n",
    "        self.side4 = nn.Conv2d(64, out_ch, 3, padding=1)\n",
    "        self.side5 = nn.Conv2d(64, out_ch, 3, padding=1)\n",
    "        self.side6 = nn.Conv2d(64, out_ch, 3, padding=1)\n",
    "\n",
    "        self.outconv = nn.Conv2d(6, out_ch, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hx = x\n",
    "\n",
    "        # stage 1\n",
    "        hx1 = self.stage1(hx)\n",
    "        hx = self.pool12(hx1)\n",
    "\n",
    "        # stage 2\n",
    "        hx2 = self.stage2(hx)\n",
    "        hx = self.pool23(hx2)\n",
    "\n",
    "        # stage 3\n",
    "        hx3 = self.stage3(hx)\n",
    "        hx = self.pool34(hx3)\n",
    "\n",
    "        # stage 4\n",
    "        hx4 = self.stage4(hx)\n",
    "        hx = self.pool45(hx4)\n",
    "\n",
    "        # stage 5\n",
    "        hx5 = self.stage5(hx)\n",
    "        hx = self.pool56(hx5)\n",
    "\n",
    "        # stage 6\n",
    "        hx6 = self.stage6(hx)\n",
    "        hx6up = _upsample_like(hx6, hx5)\n",
    "\n",
    "        # decoder\n",
    "        hx5d = self.stage5d(torch.cat((hx6up, hx5), 1))\n",
    "        hx5dup = _upsample_like(hx5d, hx4)\n",
    "\n",
    "        hx4d = self.stage4d(torch.cat((hx5dup, hx4), 1))\n",
    "        hx4dup = _upsample_like(hx4d, hx3)\n",
    "\n",
    "        hx3d = self.stage3d(torch.cat((hx4dup, hx3), 1))\n",
    "        hx3dup = _upsample_like(hx3d, hx2)\n",
    "\n",
    "        hx2d = self.stage2d(torch.cat((hx3dup, hx2), 1))\n",
    "        hx2dup = _upsample_like(hx2d, hx1)\n",
    "\n",
    "        hx1d = self.stage1d(torch.cat((hx2dup, hx1), 1))\n",
    "\n",
    "        # side output\n",
    "        d1 = self.side1(hx1d)\n",
    "\n",
    "        d2 = self.side2(hx2d)\n",
    "        d2 = _upsample_like(d2, d1)\n",
    "\n",
    "        d3 = self.side3(hx3d)\n",
    "        d3 = _upsample_like(d3, d1)\n",
    "\n",
    "        d4 = self.side4(hx4d)\n",
    "        d4 = _upsample_like(d4, d1)\n",
    "\n",
    "        d5 = self.side5(hx5d)\n",
    "        d5 = _upsample_like(d5, d1)\n",
    "\n",
    "        d6 = self.side6(hx6)\n",
    "        d6 = _upsample_like(d6, d1)\n",
    "\n",
    "        d0 = self.outconv(torch.cat((d1, d2, d3, d4, d5, d6), 1))\n",
    "\n",
    "        return torch.sigmoid(d0), torch.sigmoid(d1), torch.sigmoid(d2), torch.sigmoid(d3), torch.sigmoid(\n",
    "            d4), torch.sigmoid(d5), torch.sigmoid(d6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aef82d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import gc\n",
    "import tqdm\n",
    "import logging\n",
    "from strings import *\n",
    "from networks import model_detect\n",
    "import preprocessing as preprocessing\n",
    "import postprocessing as postprocessing\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def __work_mode__(path: str):\n",
    "    \"\"\"Determines the desired mode of operation\"\"\"\n",
    "    if os.path.isfile(path):  # Input is file\n",
    "        return \"file\"\n",
    "    if os.path.isdir(path):  # Input is dir\n",
    "        return \"dir\"\n",
    "    else:\n",
    "        return \"no\"\n",
    "\n",
    "\n",
    "def __save_image_file__(img, file_name, output_path, wmode):\n",
    "    \"\"\"\n",
    "    Saves the PIL image to a file\n",
    "    :param img: PIL image\n",
    "    :param file_name: File name\n",
    "    :param output_path: Output path\n",
    "    :param wmode: Work mode\n",
    "    \"\"\"\n",
    "    # create output directory if it doesn't exist\n",
    "    folder = os.path.dirname(output_path)\n",
    "    if folder != '':\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    if wmode == \"file\":\n",
    "        file_name_out = os.path.basename(output_path)\n",
    "        if file_name_out == '':\n",
    "            # Change file extension to png\n",
    "            file_name = os.path.splitext(file_name)[0] + '.png'\n",
    "            # Save image\n",
    "            img.save(os.path.join(output_path, file_name))\n",
    "            gc.collect()\n",
    "        else:\n",
    "            try:\n",
    "                # Save image\n",
    "                img.save(output_path)\n",
    "                gc.collect()\n",
    "            except OSError as e:\n",
    "                if str(e) == \"cannot write mode RGBA as JPEG\":\n",
    "                    raise OSError(\"Error! \"\n",
    "                                  \"Please indicate the correct extension of the final file, for example: .png\")\n",
    "                else:\n",
    "                    raise e\n",
    "    else:\n",
    "        # Change file extension to png\n",
    "        file_name = os.path.splitext(file_name)[0] + '.png'\n",
    "        # Save image\n",
    "        img.save(os.path.join(output_path, file_name))\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "def process(input_path, output_path, model_name=\"u2net\",\n",
    "            preprocessing_method_name=\"bbd-fastrcnn\", postprocessing_method_name=\"rtb-bnb\"):\n",
    "    \"\"\"\n",
    "    Processes the file.\n",
    "    :param input_path: The path to the image / folder with the images to be processed.\n",
    "    :param output_path: The path to the save location.\n",
    "    :param model_name: Model to use.\n",
    "    :param postprocessing_method_name: Method for image preprocessing\n",
    "    :param preprocessing_method_name: Method for image post-processing\n",
    "    \"\"\"\n",
    "    if input_path is None or output_path is None:\n",
    "        raise Exception(\n",
    "            \"Bad parameters! Please specify input path and output path.\")\n",
    "\n",
    "    model = model_detect(model_name)  # Load model\n",
    "    if not model:\n",
    "        logger.warning(\"Warning! You specified an invalid model type. \"\n",
    "                       \"For image processing, the model with the best processing quality will be used. \"\n",
    "                       \"(u2net)\")\n",
    "        # If the model line is wrong, select the model with better quality.\n",
    "        model_name = \"u2net\"\n",
    "        model = model_detect(model_name)  # Load model\n",
    "    preprocessing_method = preprocessing.method_detect(\n",
    "        preprocessing_method_name)\n",
    "    postprocessing_method = postprocessing.method_detect(\n",
    "        postprocessing_method_name)\n",
    "    wmode = __work_mode__(input_path)  # Get work mode\n",
    "    if wmode == \"file\":  # File work mode\n",
    "        image = model.process_image(\n",
    "            input_path, preprocessing_method, postprocessing_method)\n",
    "        __save_image_file__(image, os.path.basename(\n",
    "            input_path), output_path, wmode)\n",
    "    elif wmode == \"dir\":  # Dir work mode\n",
    "        # Start process\n",
    "        files = os.listdir(input_path)\n",
    "        for file in tqdm.tqdm(files, ascii=True, desc='Remove Background', unit='image'):\n",
    "            file_path = os.path.join(input_path, file)\n",
    "            image = model.process_image(\n",
    "                file_path, preprocessing_method, postprocessing_method)\n",
    "            __save_image_file__(image, file, output_path, wmode)\n",
    "    else:\n",
    "        raise Exception(\n",
    "            \"Bad input parameter! Please indicate the correct path to the file or folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45a3e806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__work_mode__(\"/Users/lapislux/Downloads/.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2715bcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "process(\"/Users/lapislux/Downloads/.jpeg\",\"/Users/lapislux/Downloads/Output_file.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61fbdfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.14.1-cp310-cp310-macosx_10_15_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.21.6 in /Users/lapislux/opt/anaconda3/envs/tf/lib/python3.10/site-packages (from onnxruntime) (1.22.3)\n",
      "Requirement already satisfied: protobuf in /Users/lapislux/opt/anaconda3/envs/tf/lib/python3.10/site-packages (from onnxruntime) (3.20.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/lapislux/opt/anaconda3/envs/tf/lib/python3.10/site-packages (from onnxruntime) (20210226132247)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /Users/lapislux/opt/anaconda3/envs/tf/lib/python3.10/site-packages (from onnxruntime) (21.3)\n",
      "Collecting coloredlogs\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting humanfriendly>=9.1\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/lapislux/opt/anaconda3/envs/tf/lib/python3.10/site-packages (from packaging->onnxruntime) (3.0.9)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, humanfriendly, coloredlogs, onnxruntime\n",
      "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 mpmath-1.3.0 onnxruntime-1.14.1 sympy-1.11.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a65b2b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
